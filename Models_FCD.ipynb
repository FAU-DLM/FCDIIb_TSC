{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Zoo for FCD TSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "#visualize Augmentation from directory!\n",
    "def looking_at_augmentation (data_generator, batchsize, path):\n",
    "    im, label = next(data_generator)\n",
    "    im = (im - np.min(im))/np.ptp(im) # to normalize all images --> matplotlib only takes pos. values between 0..1 / 0..255 \n",
    "    imgs = list(im)\n",
    "    labels = list(label)\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=3, nrows=3)\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    plt.suptitle('Augmented Images', fontsize=16)\n",
    "    plt.figure(num=None, figsize=(50, 50), dpi=100, facecolor='w', edgecolor='k')\n",
    "\n",
    "    for ax in ax.flatten():\n",
    "        ax.axis('off')\n",
    "\n",
    "    for i, im  in enumerate(imgs[:batchsize]):\n",
    "        ax = fig.add_subplot(3,3,i+1)\n",
    "        ax.imshow(im)\n",
    "        fig.set_figheight(8)\n",
    "        fig.set_figwidth(8)\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.savefig('Augmented-Images.png', dpi=300)\n",
    "\n",
    "#fast plot of training history\n",
    "def plot_history(history, modelname, path):\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    fig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))\n",
    "    axs[0].plot(hist_df.val_categorical_accuracy, lw=5, label='Validation Accuracy')\n",
    "    axs[0].plot(hist_df.categorical_accuracy, lw=5, label='Training Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].grid()\n",
    "    axs[0].legend(loc=0)\n",
    "    axs[1].plot(hist_df.val_loss, lw=5, label='Validation MLogLoss')\n",
    "    axs[1].plot(hist_df.loss, lw=5, label='Training MLogLoss')\n",
    "    axs[1].set_ylabel('MLogLoss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].grid()\n",
    "    axs[1].legend(loc=0)\n",
    "    fig.savefig(path + '\\History_{}.png' .format(modelname), dpi=300)\n",
    "    hist_df.to_csv()\n",
    "    plt.show();\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc#plotting the receiver operating characteristics --> evaluate performance cutting point vice\n",
    "def plot_roc(label, predictions, modelname, path): #IDEA: set diffrent cutting point based on ROC for ensembling   \n",
    "    roc_auc_score(label, predictions)\n",
    "    print('The ROC-Score is: {}' .format(roc_auc_score))\n",
    "\n",
    "    fpr_keras, tpr_keras, thresholds_keras = roc_curve(label, predictions)\n",
    "    auc_keras = auc(fpr_keras, tpr_keras)\n",
    "    #print(auc_keras)\n",
    "\n",
    "    fig = plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve: {}' .format(auc_keras))\n",
    "    plt.legend(loc='best')\n",
    "    fig.savefig(path + '\\ROC-Curve_{}.png' .format(modelname), dpi=300) #saving PLOT \n",
    "    plt.show()\n",
    "    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "# Source: Scikit Learn website\n",
    "# http://scikit-learn.org/stable/auto_examples/\n",
    "# model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-\n",
    "# selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "#plotting correctly classified images: https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python\n",
    "def plot_correct(vals, y_pred, y_label, modelname, path):\n",
    "    correct = np.where(y_pred==y_label)[0]\n",
    "    print (\"Found %d correct labels\" % len(correct))\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=3)\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    plt.suptitle('Correct Images', fontsize=16)\n",
    "    plt.figure(num=None, figsize=(50, 50), dpi=100, facecolor='w', edgecolor='k')\n",
    "\n",
    "    for ax in ax.flatten():\n",
    "        ax.axis('off')\n",
    "\n",
    "    for i, correct in enumerate(correct[:9]):\n",
    "        ax = fig.add_subplot(3,3,i+1)\n",
    "        ax.imshow(vals[correct])\n",
    "        ax.set_title(\"Predicted {}, Class {}\".format(y_pred[correct], y_label[correct]), fontsize=10)\n",
    "        fig.set_figheight(8)\n",
    "        fig.set_figwidth(8)\n",
    "\n",
    "    fig.savefig(path + '\\Correct_Images_{}.png' .format(modelname), dpi=100) #saving PLOT \n",
    "\n",
    "#Plotting incorrectly classified\n",
    "def plot_incorrect(vals, y_pred, y_label, filenames, modelname, path):\n",
    "    incorrect = np.where(y_pred!=y_label)[0]\n",
    "    print (\"Found %d incorrect labels\" % len(incorrect))\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=3)\n",
    "    fig.subplots_adjust(hspace=1)\n",
    "    plt.suptitle('Incorrect Images', fontsize=16)\n",
    "    plt.figure(num=None, figsize=(50, 50), dpi=100, facecolor='w', edgecolor='k')\n",
    "\n",
    "    for ax in ax.flatten():\n",
    "        ax.axis('off')\n",
    "\n",
    "    for i, incorrect in enumerate(incorrect[:9]):\n",
    "        ax = fig.add_subplot(3,3,i+1)\n",
    "        ax.imshow(vals[incorrect])\n",
    "        ax.set_title(\"Predicted {}, Class {}, Filename {}\".format(y_pred[incorrect], y_label[incorrect], filenames[incorrect]), fontsize=10)\n",
    "        fig.set_figheight(8)\n",
    "        fig.set_figwidth(8)\n",
    "\n",
    "    fig.savefig(path + '\\Incorrect_Images_{}.png' .format(modelname), dpi=100) #saving PLOT \n",
    "    \n",
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\eg38emed\\FCD\\FCD vs TSC\\keras_utils\")\n",
    "from image import *\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "print(os.listdir(r\"D:\\Doktorarbeit\\FCD\\Tiles\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "from time import time\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution1D, concatenate, SpatialDropout1D, GlobalMaxPool1D, GlobalAvgPool1D, Embedding, \\\n",
    "    Conv2D, SeparableConv1D, Add, BatchNormalization, Activation, GlobalAveragePooling2D, LeakyReLU, Flatten\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, \\\n",
    "    Lambda, Multiply, LSTM, Bidirectional, PReLU, MaxPooling1D\n",
    "from keras.layers.pooling import _GlobalPooling1D\n",
    "from keras.losses import mae, sparse_categorical_crossentropy, binary_crossentropy\n",
    "from keras.models import Model\n",
    "from keras.applications.nasnet import NASNetMobile, NASNetLarge, preprocess_input\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint, Callback, LambdaCallback\n",
    "from keras.metrics import categorical_accuracy\n",
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        # apply the following augmenters to most images\n",
    "        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "        iaa.Flipud(0.5), # vertically flip 20% of all images\n",
    "        sometimes(iaa.Affine(\n",
    "            scale={\"x\": (0.9, 1.6), \"y\": (0.9, 1.6)}, #>20 will cut part of img\n",
    "            translate_percent={\"x\": (-0.15, 0.15), \"y\": (-0.15, 0.15)}, # >20% will also cut part of img\n",
    "            rotate=(-10, 10), # 45/-45° -> works good with scale + translate to prevent cuts\n",
    "            shear=(-5, 5), # shear by -16 to +16 degrees\n",
    "            mode=ia.ALL \n",
    "        )),\n",
    "        iaa.SomeOf((0, 4), [\n",
    "                sometimes(iaa.Superpixels(p_replace=(0.3, 0.7), n_segments=(10, 100))), #superpixel-representation --> better basallamina representation \n",
    "                iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 0.1)), #small blur effects --> better representation\n",
    "                    #iaa.AverageBlur(k=(1, 3)), # k must be odd\n",
    "                    #iaa.MedianBlur(k=(1, 3)), # \n",
    "                ]),\n",
    "                iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), #cell wall represenation\n",
    "                iaa.Emboss(alpha=(0, 0.8), strength=(0, 0.5)), #cell wall represenation\n",
    "                #searching for edges or angles --> blobby mask --> better basallamina representation / nuclei\n",
    "                iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                    iaa.EdgeDetect(alpha=(0.2, 0.4)), #detects edges --> cell wall,..\n",
    "                    iaa.DirectedEdgeDetect(alpha=(0.2, 0.4), direction=(0.0, 1.0)), #direction will make edges from random directions \n",
    "                ])),\n",
    "                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.2), # add gaussian noise to images\n",
    "             iaa.OneOf([\n",
    "                    iaa.Dropout((0.05, 0.2), per_channel=0.2), #rnd remove 5% in small pixels\n",
    "                    iaa.CoarseDropout((0.05, 0.2), size_percent=(0.01, 0.02), per_channel=0.2),# rnd remove 3% in big pixels\n",
    "                ]),\n",
    "                iaa.Invert(0.01, per_channel=True), # invert color channels\n",
    "                iaa.Add((-10, 10), per_channel=0.3), # change brightness of images (by -10 to 10 of original value)\n",
    "                #iaa.AddToHueAndSaturation((-0.1, 0.1)), # change hue and saturation\n",
    "                #\n",
    "                #either change the brightness of the whole image (sometimes per channel) or change the brightness of subareas\n",
    "                iaa.OneOf([\n",
    "                    iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "                    iaa.FrequencyNoiseAlpha(\n",
    "                        exponent=(-1, 0),\n",
    "                        first=iaa.Multiply((0.9, 1.1), per_channel=True),\n",
    "                        second=iaa.ContrastNormalization((0.9, 1.1))\n",
    "                    )\n",
    "                ]),\n",
    "                sometimes(iaa.ElasticTransformation(alpha=(0, 0.5), sigma=0.1)), #still not sure: move pixels locally around\n",
    "                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.02))), #still not sure:move parts of the image around\n",
    "                sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "            ],\n",
    "                     random_order=True\n",
    "        )\n",
    "    ],\n",
    "    random_order=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 100\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "train_path = (r'C:\\Users\\eg38emed\\FCD\\kfold\\base_dir_fold_4\\train_dir')\n",
    "val_path = (r'C:\\Users\\eg38emed\\FCD\\kfold\\base_dir_fold_4\\val_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size_1 = 64\n",
    "val_batch_size = 64\n",
    "#datagenerators\n",
    "datagen_train = ImageDataGenerator(preprocessing_function=seq.augment_image,\n",
    "                            rescale=1./255)\n",
    "\n",
    "datagen_val = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "train_gen_1 = datagen_train.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=train_batch_size_1,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "val_gen = datagen_val.flow_from_directory(val_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=val_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "num_train_samples = len(train_gen_1)\n",
    "num_val_samples = len(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_at_augmentation(train_gen_1, path = train_path, batchsize=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASNetL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'NASNetL_kfold_4'\n",
    "\n",
    "base_path = (r'C:\\Users\\eg38emed\\FCD\\Models\\{}'.format(model_name))\n",
    "print(base_path)\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_classif_nasnetl():\n",
    "    inputs = Input((IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    base_model_NASNet = NASNetLarge(weights=None, include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)) \n",
    "    x = base_model_NASNet(inputs)\n",
    "    out1 = GlobalMaxPooling2D()(x)\n",
    "    out2 = GlobalAveragePooling2D()(x)\n",
    "    out3 = Flatten()(x)\n",
    "    out = Concatenate(axis=-1)([out1, out2, out3])\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(2, activation=\"softmax\", name=\"3_\")(out)\n",
    "    model = Model(inputs, out)\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[categorical_accuracy, auc_roc])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_classif_nasnetl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\eg38emed\\FCD\\FCD vs TSC\\keras_utils\")\n",
    "from keras_lr_finder import LRFinder\n",
    "\n",
    "lr_gen = datagen_train.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                        batch_size=5000,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "x_lr_train,y_lr_train= lr_gen.next();x_lr_train.shape\n",
    "lr_finder = LRFinder(model)\n",
    "\n",
    "lr_finder.find(x_lr_train, y_lr_train, 0.000001, 0.1, batch_size=64, epochs=4)\n",
    "lr_finder.plot_loss(n_skip_beginning=1, n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clr_callback\n",
    "from keras.callbacks import CSVLogger\n",
    "def get_callbacks_clr(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=6, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    clr = clr_callback.CyclicLR(base_lr=0.00001, max_lr=0.0001,\n",
    "                        step_size=num_train_samples/train_batch_size_1/2)\n",
    "    csv_logger = CSVLogger(filename = base_path + \"\\\\model_history_{}_toplayer.csv\".format(model_name), append=True)\n",
    "    return [clr, earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "def get_callbacks(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=10, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    csv_logger = CSVLogger(filename = base_path + \"\\\\model_history_{}_ALL.csv\".format(model_name), append=True)\n",
    "    return [earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "name_weights = (base_path + \"\\\\{}.h5\".format(model_name))\n",
    "callbacks_list = get_callbacks_clr(name_weights = name_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen_1, \n",
    "                    steps_per_epoch=train_gen_1.samples // train_batch_size_1, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=20, verbose=1,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, modelname = model_name, path=base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the data_frame: Path, ID, Label, Image\n",
    "path = val_path\n",
    "fcd = path + '\\FCD'\n",
    "tsc = path + '\\TSC'\n",
    "\n",
    "#fcd folder\n",
    "df = pd.DataFrame({'path': glob(os.path.join(fcd,'*.png'))})\n",
    "df['id'] = df.path.map(lambda x: x.split('\\\\')[6].split('.')[0]) \n",
    "df['label'] = 0\n",
    "\n",
    "#tsc folder\n",
    "df_pos = pd.DataFrame({'path': glob(os.path.join(tsc,'*.png'))})\n",
    "df_pos['id'] = df_pos.path.map(lambda x: x.split('\\\\')[6].split('.')[0]) \n",
    "df_pos['label'] = 1\n",
    "\n",
    "#both\n",
    "df_train = pd.concat([df, df_pos])\n",
    "\n",
    "#add images\n",
    "df_train['image'] = df_train['path'].map(imread)\n",
    "\n",
    "print(df_train.head())\n",
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = datagen_test.flow_from_directory(val_path, \n",
    "                                                  batch_size = batch_size, \n",
    "                                                  shuffle=False,#FALSEFALSEFALSEFALSEFALSEFALSEFALSEFALSEFALSEFALSEFALSEFALSE\n",
    "                                                  target_size=(96, 96), \n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting images out of df\n",
    "imgs = []\n",
    "for img in df_train['image']:\n",
    "    imgs.append(img)\n",
    "        \n",
    "X = np.asarray(imgs)\n",
    "y = to_categorical(df_train['label'])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im=X[0]\n",
    "plt.imshow(im)\n",
    "print(df_train.iloc[0])\n",
    "filenames = test_generator.filenames\n",
    "print(filenames[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model on validation-data + test_datagen --> weights of best training epoch will be used\n",
    "model_VGG = get_model_classif_VGG_base_trainable()\n",
    "model_VGG.load_weights(\"VGG_FCD_All.h5\")\n",
    "val_loss, val_acc = \\\n",
    "model_VGG.evaluate_generator(test_generator, \n",
    "                             steps=len(df_train),\n",
    "                             verbose=1)\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_acc:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "predictions = model_VGG.predict_generator(test_generator, \n",
    "                                          steps=len(df_train), \n",
    "                                          workers=6, \n",
    "                                          use_multiprocessing=False, \n",
    "                                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the true labels\n",
    "y_label = np.argmax(y, axis=1)\n",
    "print(y_label)\n",
    "\n",
    "df_preds = pd.DataFrame(predictions, columns=['no_tumor_tissue', 'has_tumor_tissue'])\n",
    "print(df_preds.head())\n",
    "# Get the predicted labels as probabilities\n",
    "y_pred = df_preds['has_tumor_tissue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe change pos/neg cutoff:\n",
    "plot_roc(y_label, y_pred, modelname='VGG')\n",
    "\n",
    "cm = confusion_matrix(y_label, y_pred.round())\n",
    "cm_plot_labels = ['FCD', 'TSC']\n",
    "\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix VGG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rounding predictions + make them int --> compare to label / heatmap\n",
    "y_pred = y_pred.round()\n",
    "y_pred_int = []\n",
    "for i in y_pred:\n",
    "    if i == 1.0:\n",
    "        y_pred_int.append(1)\n",
    "    else:\n",
    "        y_pred_int.append(0)\n",
    "\n",
    "y_pred_int = np.asarray(y_pred_int)\n",
    "print((y_pred_int.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correct(X, y_pred_int, y_label, modelname='VGG')\n",
    "plot_incorrect(X, y_pred_int, y_label, modelname='VGG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASNetM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'NASNetM_kfold4'\n",
    "base_path = (r'C:\\Users\\eg38emed\\FCD\\Models\\{}'.format(model_name))\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_classif_nasnetm():\n",
    "    inputs = Input((IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    base_model_NASNet = NASNetMobile(include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    x = base_model_NASNet(inputs)\n",
    "    out1 = GlobalMaxPooling2D()(x)\n",
    "    out2 = GlobalAveragePooling2D()(x)\n",
    "    out3 = Flatten()(x)\n",
    "    out = Concatenate(axis=-1)([out1, out2, out3])\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(2, activation=\"softmax\", name=\"3_\")(out)\n",
    "    model_NASNetM = Model(inputs, out)\n",
    "    model_NASNetM.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[categorical_accuracy, auc_roc])\n",
    "    model_NASNetM.summary()\n",
    "    return model_NASNetM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NASNetM = get_model_classif_nasnetm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_lr_finder import LRFinder\n",
    "\n",
    "lr_gen = datagen_train.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                        batch_size=5000,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "x_lr_train,y_lr_train= lr_gen.next()\n",
    "print(x_lr_train.shape)\n",
    "lr_finder = LRFinder(model_NASNetM)\n",
    "\n",
    "lr_finder.find(x_lr_train, y_lr_train, 0.000001, 0.1, batch_size=128, epochs=4)\n",
    "lr_finder.plot_loss(n_skip_beginning=1, n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clr_callback\n",
    "from keras.callbacks import CSVLogger\n",
    "def get_callbacks_clr(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=10, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    clr = clr_callback.CyclicLR(base_lr=0.00001, max_lr=0.0005,\n",
    "                        step_size=num_train_samples/train_batch_size_1/2)\n",
    "    csv_logger = CSVLogger(filename = base_path + \"\\\\model_history_{}_ALL.csv\".format(model_name), append=True)\n",
    "    return [clr, earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "def get_callbacks(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    csv_logger = CSVLogger(filename = base_path + \"\\\\model_history_{}_ALL.csv\".format(model_name), append=True)\n",
    "    return [earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "name_weights = (base_path + \"\\\\{}.h5\".format(model_name))\n",
    "callbacks_list = get_callbacks_clr(name_weights = name_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_NASNetM.fit_generator(train_gen_1, \n",
    "                    steps_per_epoch=train_gen_1.samples // train_batch_size_1, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=30, verbose=1,\n",
    "                    callbacks=callbacks_list)\n",
    "plot_history(history, modelname = model_name, path=base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Xception_kfold4'\n",
    "base_path = (r'C:\\Users\\eg38emed\\FCD\\Models\\{}'.format(model_name))\n",
    "print(base_path)\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications, optimizers\n",
    "def get_model_classif_X_base_nottrainable():\n",
    "    base_model = applications.Xception(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    print('Model loaded.')\n",
    "    i=0\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "        print(i,layer.name)\n",
    "        i=i+1\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x) #from 0.2\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "    model_X = Model(inputs=base_model.input, outputs=predictions)\n",
    "    adam = optimizers.Adam()\n",
    "    model_X.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[categorical_accuracy, auc_roc])\n",
    "    model_X.summary()\n",
    "    \n",
    "    return model_X\n",
    "\n",
    "def get_model_classif_Xception():\n",
    "    base_model = applications.Xception(weights=None, include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "    model_X = Model(inputs=base_model.input, outputs=predictions)\n",
    "    adam = optimizers.Adam()\n",
    "    model_X.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[categorical_accuracy, auc_roc])\n",
    "    model_X.summary()\n",
    "\n",
    "    return model_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_X = get_model_classif_X_base_nottrainable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\eg38emed\\FCD\\FCD vs TSC\\keras_utils\")\n",
    "from keras_lr_finder import LRFinder\n",
    "\n",
    "lr_gen = datagen_train.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                        batch_size=4000,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "x_lr_train,y_lr_train= lr_gen.next();x_lr_train.shape\n",
    "lr_finder = LRFinder(model_X)\n",
    "\n",
    "lr_finder.find(x_lr_train, y_lr_train, 0.000001, 0.1, batch_size=64, epochs=4)\n",
    "lr_finder.plot_loss(n_skip_beginning=1, n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clr_callback\n",
    "from keras.callbacks import CSVLogger\n",
    "def get_callbacks_clr(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    clr = clr_callback.CyclicLR(base_lr=0.00001, max_lr=0.0001,\n",
    "                        step_size=num_train_samples/train_batch_size_1/2)\n",
    "    csv_logger = CSVLogger(filename = base_path + \"\\\\model_history_{}_toplayer.csv\".format(model_name), append=True)\n",
    "    return [clr, earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "def get_callbacks(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    csv_logger = CSVLogger(filename = base_path + \"\\\\model_history_{}_ALL.csv\".format(model_name), append=True)\n",
    "    return [earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "name_weights = (base_path + \"\\\\{}_toplayer.h5\".format(model_name))\n",
    "callbacks_list = get_callbacks_clr(name_weights = name_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_X.fit_generator(train_gen_1, \n",
    "                    steps_per_epoch=train_gen_1.samples // train_batch_size_1, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=20, verbose=1,\n",
    "                    callbacks=callbacks_list)\n",
    "\n",
    "plot_history(history, modelname = model_name, path=base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_X = get_model_classif_Xception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\eg38emed\\FCD\\FCD vs TSC\\keras_utils\")\n",
    "from keras_lr_finder import LRFinder\n",
    "\n",
    "lr_gen = datagen_train.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=4000,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "x_lr_train,y_lr_train= lr_gen.next();x_lr_train.shape\n",
    "lr_finder = LRFinder(model_X)\n",
    "\n",
    "lr_finder.find(x_lr_train, y_lr_train, 0.000001, 0.1, batch_size=64, epochs=4)\n",
    "lr_finder.plot_loss(n_skip_beginning=1, n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clr_callback\n",
    "def get_callbacks_clr(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    clr = clr_callback.CyclicLR(base_lr=0.0001, max_lr=0.0005,\n",
    "                        step_size=num_train_samples/train_batch_size_1/2)\n",
    "    csv_logger = CSVLogger(filename = base_path + \"\\\\model_history_{}_ALL.csv\".format(modelname), append=True)\n",
    "    return [clr, earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "def get_callbacks(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    csv_logger = CSVLogger(filename = base_path + \"\\\\model_history_{}_ALL.csv\".format(modelname), append=True)\n",
    "    return [earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "name_weights = (base_path + \"\\\\{}_ALL.h5\".format(model_name))\n",
    "callbacks_list = get_callbacks_clr(name_weights = name_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_X.load_weights(base_path + \"\\\\{}_toplayer.h5\".format(model_name))\n",
    "history = model_X.fit_generator(train_gen_1, \n",
    "                    steps_per_epoch=train_gen_1.samples // train_batch_size_1, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=100, verbose=1,\n",
    "                    callbacks=callbacks_list)\n",
    "\n",
    "plot_history(history, modelname = model_name, path=base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception + NASNetM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Xception_NASNetM'\n",
    "base_path = (r'C:\\Users\\eg38emed\\FCD\\Models\\{}'.format(model_name))\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_classif_nasnet_x():\n",
    "    # Model Idea Xception + NASNetM\n",
    "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    xception = applications.Xception(weights='imagenet', include_top=False, input_shape=input_shape)  \n",
    "    nas_net = NASNetMobile(weights=None, include_top=False, input_shape=input_shape)\n",
    "\n",
    "    outputs = Concatenate(axis=-1)([GlobalAveragePooling2D()(xception(inputs)),\n",
    "                                    GlobalAveragePooling2D()(nas_net(inputs))])\n",
    "    outputs = Dropout(0.5)(outputs)\n",
    "    outputs = Dense(2, activation='softmax')(outputs)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[categorical_accuracy, auc_roc])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NASNetM_X = get_model_classif_nasnet_x()\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\eg38emed\\FCD\\FCD vs TSC\\keras_utils\")\n",
    "from keras_lr_finder import LRFinder\n",
    "\n",
    "lr_gen = datagen_train.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=4000,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "x_lr_train,y_lr_train= lr_gen.next();x_lr_train.shape\n",
    "lr_finder = LRFinder(model_X)\n",
    "\n",
    "lr_finder.find(x_lr_train, y_lr_train, 0.000001, 0.1, batch_size=64, epochs=4)\n",
    "lr_finder.plot_loss(n_skip_beginning=1, n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clr_callback\n",
    "def get_callbacks_clr(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    clr = clr_callback.CyclicLR(base_lr=0.0001, max_lr=0.0005,\n",
    "                        step_size=num_train_samples/train_batch_size_1/2)\n",
    "    csv_logger = CSVLogger(filename = base_path + \"model_history_{}_ALL.csv\".format(modelname), append=True)\n",
    "    return [clr, earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "def get_callbacks(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    csv_logger = CSVLogger(filename = base_path + \"model_history_{}_ALL.csv\".format(modelname), append=True)\n",
    "    return [earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "name_weights = (base_path + \"\\\\{}.h5\".format(model_name))\n",
    "callbacks_list = get_callbacks_clr(name_weights = name_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_NASNetM_X.fit_generator(train_gen_1, \n",
    "                    steps_per_epoch=train_gen_1.samples // train_batch_size_1, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=100, verbose=1,\n",
    "                    callbacks=callbacks_list)\n",
    "\n",
    "plot_history(history, modelname = model_name, path=base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ResNet'\n",
    "base_path = (r'C:\\Users\\eg38emed\\FCD\\Models\\{}'.format(model_name))\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications, optimizers\n",
    "def get_model_classif_resnet_basenottrainable():\n",
    "    base_model = applications.resnet_v2.ResNet50V2(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    print('Model loaded.')\n",
    "    i=0\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "        print(i,layer.name)\n",
    "        i=i+1\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x) #from 0.2\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "    model_X = Model(inputs=base_model.input, outputs=predictions)\n",
    "    adam = optimizers.Adam()\n",
    "    model_X.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[categorical_accuracy, auc_roc])\n",
    "    model_X.summary()\n",
    "    \n",
    "    return model_X\n",
    "\n",
    "def get_model_classif_resnet():\n",
    "    base_model = applications.resnet_v2.ResNet50V2(weights=None, include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "    model_X = Model(inputs=base_model.input, outputs=predictions)\n",
    "    adam = optimizers.Adam()\n",
    "    model_X.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[categorical_accuracy, auc_roc])\n",
    "    model_X.summary()\n",
    "\n",
    "    return model_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_classif_resnet_basenottrainable()\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\eg38emed\\FCD\\FCD vs TSC\\keras_utils\")\n",
    "from keras_lr_finder import LRFinder\n",
    "\n",
    "lr_gen = datagen_train.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=4000,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "x_lr_train,y_lr_train= lr_gen.next();x_lr_train.shape\n",
    "lr_finder = LRFinder(model)\n",
    "\n",
    "lr_finder.find(x_lr_train, y_lr_train, 0.000001, 0.1, batch_size=64, epochs=4)\n",
    "lr_finder.plot_loss(n_skip_beginning=1, n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clr_callback\n",
    "def get_callbacks_clr(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    clr = clr_callback.CyclicLR(base_lr=0.0001, max_lr=0.0005,\n",
    "                        step_size=num_train_samples/train_batch_size_1/2)\n",
    "    csv_logger = CSVLogger(filename = base_path + \"model_history_{}_toplayer.csv\".format(modelname), append=True)\n",
    "    return [clr, earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "def get_callbacks(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    csv_logger = CSVLogger(filename = base_path + \"model_history_{}_ALL.csv\".format(modelname), append=True)\n",
    "    return [earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "name_weights = (base_path + \"\\\\{}_toplayer.h5\".format(model_name))\n",
    "callbacks_list = get_callbacks_clr(name_weights = name_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen_1, \n",
    "                    steps_per_epoch=train_gen_1.samples // train_batch_size_1, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=12, verbose=1,\n",
    "                    callbacks=callbacks_list)\n",
    "\n",
    "plot_history(history, modelname = model_name, path=base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_classif_resnet_basenottrainable()\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\eg38emed\\FCD\\FCD vs TSC\\keras_utils\")\n",
    "from keras_lr_finder import LRFinder\n",
    "\n",
    "lr_gen = datagen_train.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=4000,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "x_lr_train,y_lr_train= lr_gen.next();x_lr_train.shape\n",
    "lr_finder = LRFinder(model)\n",
    "\n",
    "lr_finder.find(x_lr_train, y_lr_train, 0.000001, 0.1, batch_size=64, epochs=4)\n",
    "lr_finder.plot_loss(n_skip_beginning=1, n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clr_callback\n",
    "def get_callbacks_clr(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    clr = clr_callback.CyclicLR(base_lr=0.0001, max_lr=0.0005,\n",
    "                        step_size=num_train_samples/train_batch_size_1/2)\n",
    "    csv_logger = CSVLogger(filename = base_path + \"model_history_{}_ALL.csv\".format(modelname), append=True)\n",
    "    return [clr, earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "def get_callbacks(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    csv_logger = CSVLogger(filename = base_path + \"model_history_{}_ALL.csv\".format(modelname), append=True)\n",
    "    return [earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "name_weights = (base_path + \"\\\\{}_ALL.h5\".format(model_name))\n",
    "callbacks_list = get_callbacks_clr(name_weights = name_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen_1, \n",
    "                    steps_per_epoch=train_gen_1.samples // train_batch_size_1, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=100, verbose=1,\n",
    "                    callbacks=callbacks_list)\n",
    "\n",
    "plot_history(history, modelname = model_name, path=base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DenseNet'\n",
    "base_path = (r'C:\\Users\\eg38emed\\FCD\\Models\\{}'.format(model_name))\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications, optimizers\n",
    "def get_model_classif_densenet_basenottrainable():\n",
    "    base_model = applications.densenet.DenseNet169(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    print('Model loaded.')\n",
    "    i=0\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "        print(i,layer.name)\n",
    "        i=i+1\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x) #from 0.2\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "    model_X = Model(inputs=base_model.input, outputs=predictions)\n",
    "    adam = optimizers.Adam()\n",
    "    model_X.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[categorical_accuracy, auc_roc])\n",
    "    model_X.summary()\n",
    "    \n",
    "    return model_X\n",
    "\n",
    "def get_model_classif_densenet():\n",
    "    base_model = applications.densenet.DenseNet169(weights=None, include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "    model_X = Model(inputs=base_model.input, outputs=predictions)\n",
    "    adam = optimizers.Adam()\n",
    "    model_X.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[categorical_accuracy, auc_roc])\n",
    "    model_X.summary()\n",
    "\n",
    "    return model_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_classif_densenet_basenottrainable()\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\eg38emed\\FCD\\FCD vs TSC\\keras_utils\")\n",
    "from keras_lr_finder import LRFinder\n",
    "\n",
    "lr_gen = datagen_train.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=4000,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "x_lr_train,y_lr_train= lr_gen.next();x_lr_train.shape\n",
    "lr_finder = LRFinder(model)\n",
    "\n",
    "lr_finder.find(x_lr_train, y_lr_train, 0.000001, 0.1, batch_size=64, epochs=4)\n",
    "lr_finder.plot_loss(n_skip_beginning=1, n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clr_callback\n",
    "def get_callbacks_clr(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    clr = clr_callback.CyclicLR(base_lr=0.0001, max_lr=0.0005,\n",
    "                        step_size=num_train_samples/train_batch_size_1/2)\n",
    "    csv_logger = CSVLogger(filename = base_path + \"model_history_{}_toplayer.csv\".format(modelname), append=True)\n",
    "    return [clr, earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "def get_callbacks(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    csv_logger = CSVLogger(filename = base_path + \"model_history_{}_ALL.csv\".format(modelname), append=True)\n",
    "    return [earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "name_weights = (base_path + \"\\\\{}.h5\".format(model_name))\n",
    "callbacks_list = get_callbacks_clr(name_weights = name_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen_1, \n",
    "                    steps_per_epoch=train_gen_1.samples // train_batch_size_1, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=12, verbose=1,\n",
    "                    callbacks=callbacks_list)\n",
    "\n",
    "plot_history(history, modelname = model_name, path=base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_classif_densenet()\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\eg38emed\\FCD\\FCD vs TSC\\keras_utils\")\n",
    "from keras_lr_finder import LRFinder\n",
    "\n",
    "lr_gen = datagen_train.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=4000,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "x_lr_train,y_lr_train= lr_gen.next();x_lr_train.shape\n",
    "lr_finder = LRFinder(model)\n",
    "\n",
    "lr_finder.find(x_lr_train, y_lr_train, 0.000001, 0.1, batch_size=64, epochs=4)\n",
    "lr_finder.plot_loss(n_skip_beginning=1, n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clr_callback\n",
    "def get_callbacks_clr(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    clr = clr_callback.CyclicLR(base_lr=0.0001, max_lr=0.0005,\n",
    "                        step_size=num_train_samples/train_batch_size_1/2)\n",
    "    csv_logger = CSVLogger(filename = base_path + \"model_history_{}_ALL.csv\".format(modelname), append=True)\n",
    "    return [clr, earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "def get_callbacks(name_weights):\n",
    "    ReduceLR = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5, verbose=1, mode='auto', cooldown=5, min_lr=0.00005)\n",
    "    earlystopping = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=15, verbose=1, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(name_weights, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "    csv_logger = CSVLogger(filename = base_path + \"model_history_{}_ALL.csv\".format(modelname), append=True)\n",
    "    return [earlystopping, ReduceLR, checkpoint, csv_logger]\n",
    "\n",
    "name_weights = (base_path + \"\\\\{}_ALL.h5\".format(model_name))\n",
    "callbacks_list = get_callbacks_clr(name_weights = name_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen_1, \n",
    "                    steps_per_epoch=train_gen_1.samples // train_batch_size_1, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_gen.samples // val_batch_size,\n",
    "                    epochs=100, verbose=1,\n",
    "                    callbacks=callbacks_list)\n",
    "\n",
    "plot_history(history, modelname = model_name, path=base_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
