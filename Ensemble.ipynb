{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-Do:\n",
    "- Model Idea --> Merging NasNetM + Xception in GlobalAvgPooling Layer --> Concat --> Dropout --> Dense\n",
    "- understanding Prediction-Process\n",
    "- Ensemble Methods Bagging / shallow classifier on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.zip', 'test', 'train_labels.csv.zip', 'train.zip', 'sample_submission.csv.zip', 'train_labels.csv', 'train']\n",
      "57458\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "from time import time\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution1D, concatenate, SpatialDropout1D, GlobalMaxPool1D, GlobalAvgPool1D, Embedding, \\\n",
    "    Conv2D, SeparableConv1D, Add, BatchNormalization, Activation, GlobalAveragePooling2D, LeakyReLU, Flatten\n",
    "from keras.layers import Dense, Input, Dropout, MaxPooling2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, \\\n",
    "    Lambda, Multiply, LSTM, Bidirectional, PReLU, MaxPooling1D\n",
    "from keras.layers.pooling import _GlobalPooling1D\n",
    "from keras.losses import mae, sparse_categorical_crossentropy, binary_crossentropy\n",
    "from keras.models import Model\n",
    "from keras.applications.nasnet import NASNetMobile, NASNetLarge, preprocess_input\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint, Callback, LambdaCallback\n",
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "file_path = '/home/Deep_Learner/work/local/histopathologic-cancer-detection/train'\n",
    "print(os.listdir(\"/home/Deep_Learner/work/local/histopathologic-cancer-detection\"))\n",
    "print(len(os.listdir('/home/Deep_Learner/work/local/histopathologic-cancer-detection/test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing data without augmentation\n",
    "def show_data(df, file_path):\n",
    "    fig, ax = plt.subplots(2,5, figsize=(20,5))\n",
    "    for i, row in enumerate(df.itertuples()):\n",
    "        path = os.path.join(file_path, row.id)\n",
    "        img = Image.open(path+'.tif')\n",
    "        w,h = img.size\n",
    "        cropped = img.crop((w//2 - 32//2, h//2 - 32//2, w//2 + 32//2, h//2 + 32//2))\n",
    "        box = patches.Rectangle((32,32),32,32,linewidth=2,edgecolor='r', facecolor='none')\n",
    "        ax[0,i].imshow(img)\n",
    "        ax[0,i].add_patch(box)\n",
    "        ax[0,i].set_title(\"Label: {}\".format(row.label))\n",
    "        ax[1,i].imshow(cropped)\n",
    "        ax[0,0].set_ylabel('Sample', size='large')\n",
    "        ax[1,0].set_ylabel('Cropped', size='large')\n",
    "                \n",
    "def get_id_from_file_path(file_path):\n",
    "    return file_path.split(os.path.sep)[-1].replace('.tif', '')\n",
    "\n",
    "#dataaugmentation from https://imgaug.readthedocs.io/en/latest/index.html\n",
    "def chunker(seq, size): #slices input(seq) into batches with the size=batch_size\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def get_seq():#image augmentation\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.4, aug)\n",
    "    seq = iaa.Sequential(\n",
    "        [\n",
    "            # apply the following augmenters to most images\n",
    "            iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "            iaa.Flipud(0.5), # vertically flip 20% of all images\n",
    "            sometimes(iaa.Affine(\n",
    "                scale={\"x\": (0.9, 1.2), \"y\": (0.9, 1.2)}, #>20 will cut part of img\n",
    "                translate_percent={\"x\": (-0.15, 0.15), \"y\": (-0.15, 0.15)}, # >20% will also cut part of img\n",
    "                rotate=(-10, 10), # 45/-45Â° -> works good with scale + translate to prevent cuts\n",
    "                #shear=(-5, 5), # shear by -16 to +16 degrees\n",
    "                mode=ia.ALL \n",
    "            )),\n",
    "            iaa.SomeOf((0, 3), [\n",
    "                    sometimes(iaa.Superpixels(p_replace=(0, 0.8), n_segments=(10, 200))), #superpixel-representation --> better basallamina representation \n",
    "                    iaa.OneOf([\n",
    "                        #iaa.GaussianBlur((0, 1)), #dont know\n",
    "                        iaa.AverageBlur(k=(3, 5)), # k must be odd\n",
    "                        iaa.MedianBlur(k=(3, 5)), # \n",
    "                    ]),\n",
    "                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), #cell wall represenation\n",
    "                    iaa.Emboss(alpha=(0, 1.0), strength=(0, 1.0)), #cell wall represenation\n",
    "                    #searching for edges or angles --> blobby mask --> better basallamina representation / nuclei\n",
    "                    iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                        iaa.EdgeDetect(alpha=(0.2, 1.0)),\n",
    "                        iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
    "                    ])),\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.2), # add gaussian noise to images\n",
    "                 iaa.OneOf([\n",
    "                        iaa.Dropout((0.01, 0.03), per_channel=0.2), #rnd remove 5% in small pixels\n",
    "                        iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),# rnd remove 3% in big pixels\n",
    "                    ]),\n",
    "                    #iaa.Invert(0.01, per_channel=True), # invert color channels\n",
    "                    #iaa.Add((-10, 10), per_channel=0.3), # change brightness of images (by -10 to 10 of original value)\n",
    "                    iaa.AddToHueAndSaturation((-0.2, 0.2)), # change hue and saturation\n",
    "                    #\n",
    "                    #either change the brightness of the whole image (sometimes per channel) or change the brightness of subareas\n",
    "                    iaa.OneOf([\n",
    "                        #iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "                        #iaa.FrequencyNoiseAlpha(\n",
    "                            #exponent=(-1, 0),\n",
    "                            #first=iaa.Multiply((0.9, 1.1), per_channel=True),\n",
    "                            #second=iaa.ContrastNormalization((0.9, 1.1))\n",
    "                        #)\n",
    "                    ]),\n",
    "                    sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), #still not sure: move pixels locally around\n",
    "                    sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), #still not sure:move parts of the image around\n",
    "                    #sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "                ],\n",
    "                         random_order=True\n",
    "            )\n",
    "        ],\n",
    "        random_order=True\n",
    "    )\n",
    "    return seq\n",
    "\n",
    "#new imagedatagenerator\n",
    "def data_gen(list_files, id_label_map, batch_size, augment=False): #returns a generator function / dataaugmentation off by default\n",
    "    seq = get_seq()\n",
    "    while True:\n",
    "        shuffle(list_files)\n",
    "        for batch in chunker(list_files, batch_size):\n",
    "            X = [cv2.imread(x) for x in batch]\n",
    "            Y = [id_label_map[get_id_from_file_path(x)] for x in batch]\n",
    "            if augment:\n",
    "                X = seq.augment_images(X)\n",
    "            X = [preprocess_input(x.astype(np.float32)) for x in X]#.astype(np.float32) to prevent true divide error                \n",
    "            yield np.array(X), np.array(Y) # --> yield works like a buffer over each iteration\n",
    "\n",
    "#visualize data-augmentation\n",
    "def looking_at_augmentation (data_generator, x, y, batch_size, augmentation):\n",
    "    datagen = data_generator(x, y, batch_size, augmentation)# initialize custom data-generator\n",
    "    im, label = next(datagen)\n",
    "    \n",
    "    im = (im - np.min(im))/np.ptp(im) # to normalize all images --> matplotlib only takes pos. values between 0..1 / 0..255 \n",
    "    imgs = list(im)\n",
    "    labels = list(label)\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=3, nrows=3)\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    plt.suptitle('Augmented Images', fontsize=16)\n",
    "    plt.figure(num=None, figsize=(50, 50), dpi=100, facecolor='w', edgecolor='k')\n",
    "\n",
    "    for ax in ax.flatten():\n",
    "        ax.axis('off')\n",
    "\n",
    "    for i, im  in enumerate(imgs):\n",
    "        ax = fig.add_subplot(3,3,i+1)\n",
    "        ax.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "        fig.set_figheight(8)\n",
    "        fig.set_figwidth(8)\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.savefig('Augmented-Images.png', dpi=100)\n",
    "\n",
    "#fast plot of training history\n",
    "def plot_history(history, modelname):\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    fig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))\n",
    "    axs[0].plot(hist_df.val_acc, lw=5, label='Validation Accuracy')\n",
    "    axs[0].plot(hist_df.acc, lw=5, label='Training Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].grid()\n",
    "    axs[0].legend(loc=0)\n",
    "    axs[1].plot(hist_df.val_loss, lw=5, label='Validation MLogLoss')\n",
    "    axs[1].plot(hist_df.loss, lw=5, label='Training MLogLoss')\n",
    "    axs[1].set_ylabel('MLogLoss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].grid()\n",
    "    axs[1].legend(loc=0)\n",
    "    fig.savefig('History_{}.png' .format(modelname), dpi=300)\n",
    "    plt.show();\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc#plotting the receiver operating characteristics --> evaluate performance cutting point vice\n",
    "def plot_roc(label, predictions): #IDEA: set diffrent cutting point based on ROC for ensembling   \n",
    "    roc_auc_score(label, predictions)\n",
    "    print('The ROC-Score is: {}' .format(roc_auc_score))\n",
    "\n",
    "    fpr_keras, tpr_keras, thresholds_keras = roc_curve(label, predictions)\n",
    "    auc_keras = auc(fpr_keras, tpr_keras)\n",
    "    #print(auc_keras)\n",
    "\n",
    "    fig = plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve: {}' .format(auc_keras))\n",
    "    plt.legend(loc='best')\n",
    "    fig.savefig('ROC-Curve.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "# Source: Scikit Learn website\n",
    "# http://scikit-learn.org/stable/auto_examples/\n",
    "# model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-\n",
    "# selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "from scipy.misc import imread\n",
    "#list of tiffs to array to plot_correct / incorrect-images + rounding predictions to compare to labels\n",
    "def prep_im_label (val, y_pred):\n",
    "    vals = []\n",
    "    for i in val:\n",
    "        vals.append(imread(i))\n",
    "        #q = q+1\n",
    "        #print(q)\n",
    "        #print(i)\n",
    "    vals = np.asarray(vals)    \n",
    "    print(vals.shape)\n",
    "    y_pred = np.round(y_pred)\n",
    "    return(vals, y_pred)\n",
    "\n",
    "#plotting correctly classified images: https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python\n",
    "def plot_correct(vals, y_pred, y_label, modelname):\n",
    "    correct = np.where(y_pred==y_label)[0]\n",
    "    print (\"Found %d correct labels\" % len(correct))\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=3)\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    plt.suptitle('Correct Images', fontsize=16)\n",
    "    plt.figure(num=None, figsize=(50, 50), dpi=100, facecolor='w', edgecolor='k')\n",
    "\n",
    "    for ax in ax.flatten():\n",
    "        ax.axis('off')\n",
    "\n",
    "    for i, correct in enumerate(correct[:9]):\n",
    "        ax = fig.add_subplot(3,3,i+1)\n",
    "        ax.imshow(vals[correct])\n",
    "        ax.set_title(\"Predicted {}, Class {}\".format(y_pred[correct], y_label[correct]), fontsize=10)\n",
    "        fig.set_figheight(8)\n",
    "        fig.set_figwidth(8)\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.savefig('Correct_Images_{}.png' .format(model_name), dpi=100)\n",
    "\n",
    "#Plotting incorrectly classified\n",
    "def plot_incorrect(vals, y_pred, y_label, modelname):\n",
    "    incorrect = np.where(y_pred!=y_label)[0]\n",
    "    print (\"Found %d incorrect labels\" % len(incorrect))\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=3)\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    plt.suptitle('Incorrect Images', fontsize=16)\n",
    "    plt.figure(num=None, figsize=(50, 50), dpi=100, facecolor='w', edgecolor='k')\n",
    "\n",
    "    for ax in ax.flatten():\n",
    "        ax.axis('off')\n",
    "\n",
    "    for i, incorrect in enumerate(incorrect[:9]):\n",
    "        ax = fig.add_subplot(3,3,i+1)\n",
    "        ax.imshow(vals[incorrect])\n",
    "        ax.set_title(\"Predicted {}, Class {}\".format(y_pred[incorrect], y_label[incorrect]), fontsize=10)\n",
    "        fig.set_figheight(8)\n",
    "        fig.set_figwidth(8)\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    fig.savefig('Incorrect_Images._{}.png' .format(model_name), dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postive cases 89,116, negative cases 130,907 in training set.\n",
      "Number of labeled_files size : 220025\n",
      "Number of test_files size : 57458\n",
      "                                         id  label\n",
      "0  f38a6374c348f90b587e046aac6079959adf3835      0\n",
      "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
      "2  755db6279dae599ebb4d39a9123cce439965282d      0\n",
      "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
      "4  068aba587a4950175d04c680d38943fd488d6a9d      0\n"
     ]
    }
   ],
   "source": [
    "#datapreparation\n",
    "df_train = pd.read_csv(\"/home/Deep_Learner/work/local/histopathologic-cancer-detection/train_labels.csv\")\n",
    "id_label_map = {k:v for k,v in zip(df_train.id.values, df_train.label.values)} #constructing a dict with id to corresponding label\n",
    "\n",
    "# removing this image because it caused a training error previously\n",
    "df_train = df_train[df_train['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2']\n",
    "\n",
    "# removing this image because it's black\n",
    "df_train = df_train[df_train['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']\n",
    "\n",
    "#to show some images\n",
    "negative_cases_train = df_train[df_train[\"label\"] == 0]\n",
    "positive_cases_train = df_train[df_train[\"label\"] == 1]\n",
    "print(\"Postive cases {:,}, negative cases {:,} in training set.\".format(len(positive_cases_train), len(negative_cases_train)))\n",
    "\n",
    "labeled_files = glob('/home/Deep_Learner/work/local/histopathologic-cancer-detection/train/*.tif')\n",
    "test_files = glob('/home/Deep_Learner/work/local/histopathologic-cancer-detection/test/*.tif')\n",
    "\n",
    "#sanity check\n",
    "print(\"Number of labeled_files size :\", len(labeled_files))\n",
    "print(\"Number of test_files size :\", len(test_files))\n",
    "\n",
    "#Test_Train-Split = 0.1\n",
    "train, val = train_test_split(labeled_files, test_size=0.1, random_state=101010)\n",
    "\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 3, 3, 4032)   84916818    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 4032)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 4032)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 36288)        0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 44352)        0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 44352)        0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            44353       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 84,961,171\n",
      "Trainable params: 84,764,503\n",
      "Non-trainable params: 196,668\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model_classif_nasnetl():\n",
    "    inputs = Input((96, 96, 3))\n",
    "    base_model_NASNet = NASNetLarge(weights=None, include_top=False, input_shape=(96, 96, 3)) \n",
    "    x = base_model_NASNet(inputs)\n",
    "    out1 = GlobalMaxPooling2D()(x)\n",
    "    out2 = GlobalAveragePooling2D()(x)\n",
    "    out3 = Flatten()(x)\n",
    "    out = Concatenate(axis=-1)([out1, out2, out3])\n",
    "    out = Dropout(0.6)(out)\n",
    "    out = Dense(1, activation=\"sigmoid\", name=\"3_\")(out)\n",
    "    model_NASNetLarge = Model(inputs, out)\n",
    "    model_NASNetLarge.compile(optimizer=Adam(5e-05), loss=binary_crossentropy, metrics=['acc'])\n",
    "    model_NASNetLarge.summary()\n",
    "\n",
    "    return model_NASNetLarge\n",
    "\n",
    "model_NASNetLarge = get_model_classif_nasnetl()\n",
    "model_NASNetLarge.load_weights('NASNetL_2.weights.best.hdf5')\n",
    "print('Model NASNetLarge loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 96, 96, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 96, 96, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 48, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 48, 48, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 24, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 24, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 24, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_2 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 14,846,273\n",
      "Trainable params: 14,846,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras import optimizers\n",
    "#VGG-16\n",
    "img_width_VGG, img_height_VGG = 96, 96 #VGG\n",
    "modelname = 'VGG'\n",
    "\n",
    "def get_model_classif_VGG():\n",
    "#VGG16 network\n",
    "    base_model_VGG = applications.VGG16(weights=None, include_top=False, input_shape=(img_width_VGG, img_height_VGG, 3))\n",
    "    print('Model loaded.')\n",
    "    x = base_model_VGG.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = (Dense(256, activation='relu'))(x)\n",
    "    x = (Dropout(0.5)) (x)\n",
    "    predictions = (Dense(1, activation='sigmoid'))(x)\n",
    "    model_VGG = Model(inputs=base_model_VGG.input, outputs=predictions)\n",
    "\n",
    "    adam = optimizers.Adam(lr=0.0005)\n",
    "    model_VGG.compile(loss=binary_crossentropy,\n",
    "                  optimizer=adam,\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    model_VGG.summary()\n",
    "    return model_VGG\n",
    "\n",
    "model_VGG = get_model_classif_VGG()\n",
    "model_VGG.load_weights(\"VGG_All.weights.best.hdf5\")\n",
    "print('Model VGG16 loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NASNet (Model)                  (None, 3, 3, 1056)   4269716     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalM (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1056)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 9504)         0           NASNet[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 11616)        0           global_max_pooling2d_3[0][0]     \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 11616)        0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "3_ (Dense)                      (None, 1)            11617       dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,281,333\n",
      "Trainable params: 4,244,595\n",
      "Non-trainable params: 36,738\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model_classif_nasnetm():\n",
    "    inputs = Input((96, 96, 3))\n",
    "    base_model_NASNet = NASNetMobile(include_top=False, input_shape=(96, 96, 3))\n",
    "    x = base_model_NASNet(inputs)\n",
    "    out1 = GlobalMaxPooling2D()(x)\n",
    "    out2 = GlobalAveragePooling2D()(x)\n",
    "    out3 = Flatten()(x)\n",
    "    out = Concatenate(axis=-1)([out1, out2, out3])\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(1, activation=\"sigmoid\", name=\"3_\")(out)\n",
    "    model_NASNetM = Model(inputs, out)\n",
    "    model_NASNetM.compile(optimizer=Adam(0.0001), loss=binary_crossentropy, metrics=['acc'])\n",
    "    model_NASNetM.summary()\n",
    "\n",
    "    return model_NASNetM\n",
    "\n",
    "model_NASNetM = get_model_classif_nasnetm()\n",
    "model_NASNet.load_weights('NASNet_3.weights.best.hdf5')\n",
    "print('Model NASNetMobile loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width_X, img_height_X = 96, 96\n",
    "def get_model_classif_Xception():\n",
    "    base_model = applications.Xception(weights=None, include_top=False, input_shape=(img_width_X, img_height_X, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) #from 0.2\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    model_X = Model(inputs=base_model.input, outputs=predictions)\n",
    "    adam = optimizers.Adam(lr=0.0005)\n",
    "    model_X.compile(loss='binary_crossentropy', optimizer=adam, metrics = ['accuracy'])\n",
    "    model_X.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "model_X = get_model_classif_Xception()\n",
    "model_X.load_weights(\"Xception_All.weights.best.hdf5\")\n",
    "print('Model Xception loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_classif_nasnet_x():\n",
    "    # Model Idea Xception + NASNetM\n",
    "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    xception = applications.Xception(weights=None, include_top=False, input_shape=input_shape)  \n",
    "    nas_net = NASNetMobile(weights=None, include_top=False, input_shape=input_shape)\n",
    "\n",
    "    outputs = Concatenate(axis=-1)([GlobalAveragePooling2D()(xception(inputs)),\n",
    "                                    GlobalAveragePooling2D()(nas_net(inputs))])\n",
    "    outputs = Dropout(0.6)(outputs)\n",
    "    outputs = Dense(1, activation='sigmoid')(outputs)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(lr=0.0001, decay=0.00001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model_NASNetM_X = get_model_classif_nasnet_x()\n",
    "model_NASNetM_X.load_weights(\"still_to_get_the_best\")\n",
    "print('Model model_NASNetM_X loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding Prediction-Process\n",
    "x = file_path + 'test/test/0000ec92553fda4ce39889f9226ace43cae3364e.tif'\n",
    "X = preprocess_input(cv2.imread(x).astype(np.float32))\n",
    "preds_batch = ((model_NASNetM_X.predict(X).ravel()*model_NASNetM_X.predict(X[:, ::-1, :, :]).ravel()*model_NASNetLarge.predict(X[:, ::-1, ::-1, :]).ravel()*model_NASNetLarge.predict(X[:, :, ::-1, :]).ravel())**0.25).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-07bb108a000e>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-07bb108a000e>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    for model in model_list\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "preds_batch = []\n",
    "for model in model_list:\n",
    "    prediction = model.predict(X)\n",
    "    preds_batch.append(predictions)\n",
    "y = np.mean(preds_batch, axis=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [preds_batch.append(model.predict(X)) for model in model_list] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "256\n",
      "384\n",
      "512\n",
      "640\n",
      "768\n",
      "896\n",
      "1024\n",
      "1152\n",
      "1280\n",
      "1408\n",
      "1536\n",
      "1664\n",
      "1792\n",
      "1920\n",
      "2048\n",
      "2176\n",
      "2304\n",
      "2432\n",
      "2560\n",
      "2688\n",
      "2816\n",
      "2944\n",
      "3072\n",
      "3200\n",
      "3328\n",
      "3456\n",
      "3584\n",
      "3712\n",
      "3840\n",
      "3968\n",
      "4096\n",
      "4224\n",
      "4352\n",
      "4480\n",
      "4608\n",
      "4736\n",
      "4864\n",
      "4992\n",
      "5120\n",
      "5248\n",
      "5376\n",
      "5504\n",
      "5632\n",
      "5760\n",
      "5888\n",
      "6016\n",
      "6144\n",
      "6272\n",
      "6400\n",
      "6528\n",
      "6656\n",
      "6784\n",
      "6912\n",
      "7040\n",
      "7168\n",
      "7296\n",
      "7424\n",
      "7552\n",
      "7680\n",
      "7808\n",
      "7936\n",
      "8064\n",
      "8192\n",
      "8320\n",
      "8448\n",
      "8576\n",
      "8704\n",
      "8832\n",
      "8960\n",
      "9088\n",
      "9216\n",
      "9344\n",
      "9472\n",
      "9600\n",
      "9728\n",
      "9856\n",
      "9984\n",
      "10112\n",
      "10240\n",
      "10368\n",
      "10496\n",
      "10624\n",
      "10752\n",
      "10880\n",
      "11008\n",
      "11136\n",
      "11264\n",
      "11392\n",
      "11520\n",
      "11648\n",
      "11776\n",
      "11904\n",
      "12032\n",
      "12160\n",
      "12288\n",
      "12416\n",
      "12544\n",
      "12672\n",
      "12800\n",
      "12928\n",
      "13056\n",
      "13184\n",
      "13312\n",
      "13440\n",
      "13568\n",
      "13696\n",
      "13824\n",
      "13952\n",
      "14080\n",
      "14208\n",
      "14336\n",
      "14464\n",
      "14592\n",
      "14720\n",
      "14848\n",
      "14976\n",
      "15104\n",
      "15232\n",
      "15360\n",
      "15488\n",
      "15616\n",
      "15744\n",
      "15872\n",
      "16000\n",
      "16128\n",
      "16256\n",
      "16384\n",
      "16512\n",
      "16640\n",
      "16768\n",
      "16896\n",
      "17024\n",
      "17152\n",
      "17280\n",
      "17408\n",
      "17536\n",
      "17664\n",
      "17792\n",
      "17920\n",
      "18048\n",
      "18176\n",
      "18304\n",
      "18432\n",
      "18560\n",
      "18688\n",
      "18816\n",
      "18944\n",
      "19072\n",
      "19200\n",
      "19328\n",
      "19456\n",
      "19584\n",
      "19712\n",
      "19840\n",
      "19968\n",
      "20096\n",
      "20224\n",
      "20352\n",
      "20480\n",
      "20608\n",
      "20736\n",
      "20864\n",
      "20992\n",
      "21120\n",
      "21248\n",
      "21376\n",
      "21504\n",
      "21632\n",
      "21760\n",
      "21888\n",
      "22016\n",
      "22144\n",
      "22272\n",
      "22400\n",
      "22528\n",
      "22656\n",
      "22784\n",
      "22912\n",
      "23040\n",
      "23168\n",
      "23296\n",
      "23424\n",
      "23552\n",
      "23680\n",
      "23808\n",
      "23936\n",
      "24064\n",
      "24192\n",
      "24320\n",
      "24448\n",
      "24576\n",
      "24704\n",
      "24832\n",
      "24960\n",
      "25088\n",
      "25216\n",
      "25344\n",
      "25472\n",
      "25600\n",
      "25728\n",
      "25856\n",
      "25984\n",
      "26112\n",
      "26240\n",
      "26368\n",
      "26496\n",
      "26624\n",
      "26752\n",
      "26880\n",
      "27008\n",
      "27136\n",
      "27264\n",
      "27392\n",
      "27520\n",
      "27648\n",
      "27776\n",
      "27904\n",
      "28032\n",
      "28160\n",
      "28288\n",
      "28416\n",
      "28544\n",
      "28672\n",
      "28800\n",
      "28928\n",
      "29056\n",
      "29184\n",
      "29312\n",
      "29440\n",
      "29568\n",
      "29696\n",
      "29824\n",
      "29952\n",
      "30080\n",
      "30208\n",
      "30336\n",
      "30464\n",
      "30592\n",
      "30720\n",
      "30848\n",
      "30976\n",
      "31104\n",
      "31232\n",
      "31360\n",
      "31488\n",
      "31616\n",
      "31744\n",
      "31872\n",
      "32000\n",
      "32128\n",
      "32256\n",
      "32384\n",
      "32512\n",
      "32640\n",
      "32768\n",
      "32896\n",
      "33024\n",
      "33152\n",
      "33280\n",
      "33408\n",
      "33536\n",
      "33664\n",
      "33792\n",
      "33920\n",
      "34048\n",
      "34176\n",
      "34304\n",
      "34432\n",
      "34560\n",
      "34688\n",
      "34816\n",
      "34944\n",
      "35072\n",
      "35200\n",
      "35328\n",
      "35456\n",
      "35584\n",
      "35712\n",
      "35840\n",
      "35968\n",
      "36096\n",
      "36224\n",
      "36352\n",
      "36480\n",
      "36608\n",
      "36736\n",
      "36864\n",
      "36992\n",
      "37120\n",
      "37248\n",
      "37376\n",
      "37504\n",
      "37632\n",
      "37760\n",
      "37888\n",
      "38016\n",
      "38144\n",
      "38272\n",
      "38400\n",
      "38528\n",
      "38656\n",
      "38784\n",
      "38912\n",
      "39040\n",
      "39168\n",
      "39296\n",
      "39424\n",
      "39552\n",
      "39680\n",
      "39808\n",
      "39936\n",
      "40064\n",
      "40192\n",
      "40320\n",
      "40448\n",
      "40576\n",
      "40704\n",
      "40832\n",
      "40960\n",
      "41088\n",
      "41216\n",
      "41344\n",
      "41472\n",
      "41600\n",
      "41728\n",
      "41856\n",
      "41984\n",
      "42112\n",
      "42240\n",
      "42368\n",
      "42496\n",
      "42624\n",
      "42752\n",
      "42880\n",
      "43008\n",
      "43136\n",
      "43264\n",
      "43392\n",
      "43520\n",
      "43648\n",
      "43776\n",
      "43904\n",
      "44032\n",
      "44160\n",
      "44288\n",
      "44416\n",
      "44544\n",
      "44672\n",
      "44800\n",
      "44928\n",
      "45056\n",
      "45184\n",
      "45312\n",
      "45440\n",
      "45568\n",
      "45696\n",
      "45824\n",
      "45952\n",
      "46080\n",
      "46208\n",
      "46336\n",
      "46464\n",
      "46592\n",
      "46720\n",
      "46848\n",
      "46976\n",
      "47104\n",
      "47232\n",
      "47360\n",
      "47488\n",
      "47616\n",
      "47744\n",
      "47872\n",
      "48000\n",
      "48128\n",
      "48256\n",
      "48384\n",
      "48512\n",
      "48640\n",
      "48768\n",
      "48896\n",
      "49024\n",
      "49152\n",
      "49280\n",
      "49408\n",
      "49536\n",
      "49664\n",
      "49792\n",
      "49920\n",
      "50048\n",
      "50176\n",
      "50304\n",
      "50432\n",
      "50560\n",
      "50688\n",
      "50816\n",
      "50944\n",
      "51072\n",
      "51200\n",
      "51328\n",
      "51456\n",
      "51584\n",
      "51712\n",
      "51840\n",
      "51968\n",
      "52096\n",
      "52224\n",
      "52352\n",
      "52480\n",
      "52608\n",
      "52736\n",
      "52864\n",
      "52992\n",
      "53120\n",
      "53248\n",
      "53376\n",
      "53504\n",
      "53632\n",
      "53760\n",
      "53888\n",
      "54016\n",
      "54144\n",
      "54272\n",
      "54400\n",
      "54528\n",
      "54656\n",
      "54784\n",
      "54912\n",
      "55040\n",
      "55168\n",
      "55296\n",
      "55424\n",
      "55552\n",
      "55680\n",
      "55808\n",
      "55936\n",
      "56064\n",
      "56192\n",
      "56320\n",
      "56448\n",
      "56576\n",
      "56704\n",
      "56832\n",
      "56960\n",
      "57088\n",
      "57216\n",
      "57344\n",
      "57458\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e085ee60227b6231063a05594fff9d21ee0ed9c</td>\n",
       "      <td>5.093140e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6edc8bdcf7e2fda2e7b72ee867793ddb00ce927b</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93c660cb867f5223575965066e7b824714a6be35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0a4bc08999888cd2e0bd9ba8cb90fb1cd0da5cd8</td>\n",
       "      <td>5.775352e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>091764784311abab8ab1722e0edf4880d7c53eab</td>\n",
       "      <td>2.980081e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id         label\n",
       "0  5e085ee60227b6231063a05594fff9d21ee0ed9c  5.093140e-08\n",
       "1  6edc8bdcf7e2fda2e7b72ee867793ddb00ce927b  0.000000e+00\n",
       "2  93c660cb867f5223575965066e7b824714a6be35  0.000000e+00\n",
       "3  0a4bc08999888cd2e0bd9ba8cb90fb1cd0da5cd8  5.775352e-06\n",
       "4  091764784311abab8ab1722e0edf4880d7c53eab  2.980081e-01"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making ensembled-predictions on test-data\n",
    "batch_size = 128\n",
    "preds = []\n",
    "ids = []\n",
    "for batch in chunker(test_files, batch_size):\n",
    "    X = [preprocess_input(cv2.imread(x).astype(np.float32)) for x in batch]\n",
    "    ids_batch = [get_id_from_file_path(x) for x in batch]\n",
    "    X = np.array(X)\n",
    "    #print(X)\n",
    "    preds_batch = ((model_NASNetM_X.predict(X).ravel()*model_NASNetM_X.predict(X[:, ::-1, :, :]).ravel()*model_NASNetLarge.predict(X[:, ::-1, ::-1, :]).ravel()*model_NASNetLarge.predict(X[:, :, ::-1, :]).ravel())**0.25).tolist()\n",
    "    #print(preds_batch)\n",
    "    preds += preds_batch\n",
    "    ids += ids_batch\n",
    "    print(len(preds))\n",
    "    \n",
    "df = pd.DataFrame({'id':ids, 'label':preds})\n",
    "df.to_csv(\"baseline2_ensemble.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/Deep_Learner/.kaggle/kaggle.json'\n",
      "100%|ââââââââââââââââââââââââââââââââââââââ| 3.22M/3.22M [00:02<00:00, 1.20MB/s]\n",
      "Successfully submitted to Histopathologic Cancer Detection"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c histopathologic-cancer-detection -f baseline2_ensemble.csv -m \"NASNetL + VGG + VGG + TTA\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
